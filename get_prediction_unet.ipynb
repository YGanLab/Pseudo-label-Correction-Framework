{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os,sys\n",
    "import scipy.io as scio \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "import scipy.ndimage as ndimage\n",
    "from unet import UNet\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet(n_channels=1, n_classes=2).cuda()\n",
    "#model = nn.DataParallel(model)\n",
    "PATH = os.getcwd() + '\\\\models\\\\model_noise_75_1_8\\\\1it\\\\seg_module.model'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(filenames, ext, root):\n",
    "    images = []\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "        elif ext == '.JPG' or ext == '.tif' or ext =='.png':\n",
    "            image = ndimage.imread(filepath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_data(directory,ext):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    root_path = \"\"\n",
    "    filenames = [f for f in listdir(directory) if isfile(join(directory, f)) and f != '.DS_Store']\n",
    "    filenames = sorted(filenames)\n",
    "    return filenames, get_info(filenames, ext, directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "filenames_im, images = get_data(cwd+'\\medical_images\\\\oct_images\\\\Train','.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for j in range(len(filenames_im)):\n",
    "    im = images[j].copy()\n",
    "    im = im*1.0/np.max(im)\n",
    "    im = im.reshape((1,1,im.shape[0], -1))\n",
    "    im = torch.from_numpy(im)\n",
    "    X = Variable(im).cuda().float()\n",
    "      \n",
    "    output = model(X)\n",
    "    output2 = output.data.cpu().numpy()\n",
    "    output2 = np.squeeze(output2[0])\n",
    "\n",
    "    output2 = np.argmax(output2,0)\n",
    "    output2 = np.squeeze(output2)\n",
    "    print(np.unique(output2))\n",
    "    plt.imshow(output2)\n",
    "    plt.show()\n",
    "    save_path = cwd + '\\\\medical_images\\\\prediction\\\\' + filenames_im[j]\n",
    "    prediction.append(output2)\n",
    "    cv2.imwrite(save_path, output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
